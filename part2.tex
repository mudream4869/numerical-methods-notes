\section{LU Factorization}

In order to solve a linear system $Ax = b$,
we will introduce a method.

\subsection{Triangular system}

A triangular matrix is a square matrix with element above or beneath the diagonal are zero.
For example :
\[
    \begin{bmatrix}
        1 & 2 & 3 \\ 
        0 & 4 & 5 \\ 
        0 & 0 & 6  
    \end{bmatrix}
\]

is a upper triangular matrix.

When $A$ is a triagular matrix, Solving $Ax = b$ is simple,
and the complexity can be only $O(n^2)$, where $n$ is the width of $A$.

Observe that
\[
    \begin{bmatrix}
        3 & 5 \\ 
        6 & 7 \\ 
    \end{bmatrix}
    =
    \begin{bmatrix}
        1 & 0 \\ 
        2 & 1 \\ 
    \end{bmatrix}
    \begin{bmatrix}
        3 & 5 \\ 
        0 & -3 \\ 
    \end{bmatrix}
\]

, so we can solve

\[
    \begin{bmatrix}
        3 & 5 \\ 
        6 & 7 \\ 
    \end{bmatrix}
    x=\begin{bmatrix}9 \\ 4 \\ \end{bmatrix}
\]

by split $A$ into two triangular matrix:

\[
    \begin{bmatrix}
        1 & 0 \\ 
        2 & 1 \\ 
    \end{bmatrix}
    \begin{bmatrix}
        3 & 5 \\ 
        0 & -3 \\ 
    \end{bmatrix}
    x=\begin{bmatrix}9 \\ 4 \\ \end{bmatrix}
\]

\subsection{Gaussian Elimination}

The process of whole gaussian elimination can express as an equation :
$U = M_{n-1}M_{n-2} \dots M_1 A $, where $U$ is a Upper triangular matrix,
$M_i$ is row operation matrix. Since $M_i$ is a lower triangular matrix,
$L = M_1^{-1} \dots M_{n-1}^{-1}$ is also a lower triangular matrix,
we can have $A = LU$, which split $A$ into two triangular matrix.

\subsection{Interchange}

Notice that not all $\det A \neq 0$ can apply \textbf{gaussian elimenation}.
For instance : 
\[
    \begin{bmatrix}
        0 & 1 \\
        1 & 0 \\
    \end{bmatrix}
\]

\section{Cholesky Factorization}

\begin{theorem}
    A symmetric matrix is Positive Definite $\Leftrightarrow$
    $A = LL^T$ for some lower traingular matrix $L$
\end{theorem}

\begin{proof}
Now we try to prove forward part, While $\dim(A) = 1$ is ok. Assume $\dim(A) = n > 1$,

\[
    A = 
    \begin{bmatrix}
        \alpha & v \\
        v^T    & LL^T \\
    \end{bmatrix}
    =
    \begin{bmatrix}
        \sqrt\alpha & 0 \\
        \frac{v^T}{\sqrt\alpha}    & L \\
    \end{bmatrix}
    \begin{bmatrix}
        \sqrt\alpha & \frac{v}{\sqrt\alpha} \\
        0           & L^T \\
    \end{bmatrix}
\]
  
\end{proof}
